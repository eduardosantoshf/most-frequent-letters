%
% General structure for the revdetua class:
%
\documentclass[...]{revdetua}
\usepackage{graphicx}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}

%%%%%%%% Python code snippet %%%%%%%%

% Custom colors
\usepackage{color}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

\usepackage{listings}

% Python style for highlighting
\newcommand\pythonstyle{\lstset{
language=Python,
basicstyle=\ttm\footnotesize, %added \footnotesize to /basicstyle to make the correcy code siz
morekeywords={self},              % Add keywords here
keywordstyle=\ttb\color{deepblue},
emph={MyClass,__init__},          % Custom highlighting
emphstyle=\ttb\color{deepred},    % Custom highlighting style
stringstyle=\color{deepgreen},
%frame=tb,                         % Any extra options here
showstringspaces=false
}}


% Python environment
\lstnewenvironment{python}[1][]
{
\pythonstyle
\lstset{#1}
}
{}

% listings to highlight code
\usepackage{pythonhighlight}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%
% Valid options are:
%
%   longpaper --------- \part and \tableofcontents defined
%   shortpaper -------- \part and \tableofcontents not defined (default)
%
%   english ----------- main language is English (default)
%   portugues --------- main language is Portuguese
%
%   draft ------------- draft version
%   final ------------- final version (default)
%
%   times ------------- use times (postscript) fonts for text
%
%   mirror ------------ prints a mirror image of the paper (with dvips)
%
%   visiblelabels ----- \SL, \SN, \SP, \EL, \EN, etc. defined
%   invisiblelabels --- \SL, \SN, \SP, \EL, \EN, etc. not defined (default)
%
% Note: the final version should use the times fonts
% Note: the really final version should also use the mirror option
%

\begin{document}

\Header{1}{25}{janeiro}{2023}{0}
% Note: the month must be in Portuguese

\title{Most Frequent Letters}
\author{Eduardo Santos, nÂºmec 93107, eduardosantoshf@ua.pt} % or \author{... \and ...}
\maketitle

\begin{abstract}
The objective of this assignment was to identify the most frequent letters in text files  using different methods and to evaluate the quality of estimates regarding the exact counts. Three types of counters were implemented: an Exact Counter, a Decreasing Probability Counter, and a Frequent Counter. 
\end{abstract}

\begin{keywords}{Counting Algorithms, Data Stream Algorithms, Probabilistic Counters, Exact Counter, Decreasing Probability Counter, Frequent Counter}
\end{keywords}

\section{Introduction}

\subsection{Decreasing Probability Counter}

The aim of a probabilistic counter is to count very large numbers using only a little space to store the counter. Counting a very large number of events using an exact counter will result in a large memory usage, which is something that should be avoided, as memory is expensive, and makes a program less efficient. To mitigate this problem, probabilistic counters were created. So, for each call to an increment method on the counter, its actual value is updated with probability \textit{p}. Using this method, we are trading accuracy for the ability to count up to very large numbers with little storage space.

Even though nowadays memory is no longer scarce, this approach is still useful when treating/counting massive data volumes, when there is a need for quick and memory-efficient processing.

\subsection{Frequent Counter}

A streaming algorithm is an algorithm for processing data streams in which the input is presented as a sequence of items and can be examined in only a few passes, typically just one.
The frequent problem happens when, given a sequence of items, we want to identify those which occur most frequently. This can also be expressed as finding all items whose frequency exceeds a specified fraction of the total number of items.

\section{Problem Description}

The  goal of this assignment was to identify the most frequent letters in literary works from Project Gutenberg\cite{project} using different methods and to evaluate the quality of estimates regarding the exact counts.

In order to accomplish that, three different approaches were developed and tested:
\begin{itemize}
    \item exact counter
    \item approximate counter - decreasing probability counter with probability \(\frac{1}{\sqrt{2}^k}\)
    \item frequent counter - Misra \& Gries algorithm to identify frequent items in data streams
\end{itemize} 

The testing involved an analysis of the computational efficiency and limitations of the developed approaches was carried out, in terms of absolute and relative errors, computing the mean, minimum, and maximum of each error, as well as computing the standard deviation and variance.
Finally, for each method, the most frequent letters were identified, checking if they were in the same relative order.

\section{Implementation Description}

\subsection{Main}

Running the \textbf{main.py}, with the \textbf{--help} flag, a few running options are presented.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=1\columnwidth]{./figures/usage}
    \caption{Help Menu of the Main Program}
    \label{fig: Help Menu}
\end{figure}

The \textbf{-t} flag represents the filename of the literary work to be read and processed by the program, which can be found inside the \textbf{/texts/} directory. The \textbf{-s} flag represents the filename of the stop-words to be ignored when processing the text file. The stop-words files can be found inside the \textbf{/stop-words/} directory. After the previous parameters, we have to specify the counter type to be computed, using one of the following:
\begin{itemize}
    \item \textbf{exact} - count using the exact counter
    \item \textbf{decreasing} - count using the decreasing probability counter (with probability \(\frac{1}{\sqrt{2}^k}\))
    \item \textbf{frequent} - count using the frequent counter (we must also specify the \textit{k} parameter, using the flag \textbf{-k})
\end{itemize}

\subsection{Counter}

The \textbf{counter.py} contains the main logic of the solution, using the \textbf{ABC}\cite{abstract_base_classes} (Abstract Base Classes) Python module, the \textbf{ExactCounter}, \textbf{DecreasingProbabilityCounter}, and \textbf{FrequentCounter} classes extend the \textbf{Counter} parent class, using an OOP (object-oriented programming) model.
Inside the \textbf{Counter} class there is the \textit{read\_letters()} method, which is responsible for parsing the text file, removing the Project Gutenberg file headers and footers, all stop-words and punctuation marks, as well as converting all letters to uppercase.

\begin{python}[linenos, tabsize=1, breaklines]
def read_letters(self):
    with open(self.filename, 'r') as file:
        while True:
            line = file.readline()

            # ignore the Project Gutenberg's file headers
                if line.strip() in [header.value for header in Headers]: break
                
        while line:
            line = file.readline()

            # ignore the Project Gutenberg's file footers
            if line.strip() in [footer.value for footer in Footers]: break
            
            for words in line.split():
                # remove all stop-words and punctuation marks
                for word in regex.findall('\p{alpha}+', words):
                    for letter in word:
                        self.parsed_letters.append(letter.upper())
\end{python}

\subsection{Exact Counter}

Inside the \textbf{ExactCounter} class we can find the \textit{compute()} method, which is responsible for counting the exact number of occurrences of each letter from the literary work.

\subsection{Decreasing Probability Counter}

The \textbf{DecreasingProbabilityCounter} class implements the Decreasing Probability Counter as a probabilistic counter, with the increment being made with probability \(\frac{1}{\sqrt{2}^k}\), where \textit{k} represents the number of occurrences of each letter. If the counter has value \textit{k}, the algorithm increases the number of occurrences of the letter with the previously mentioned probability. Due to \textit{k} and the probability being inversely proportional, as \textit{k} increases, the probability of incrementing the counter will be much smaller. This method allows the counting of a large number of events using a small amount of memory.
The estimated value of the counter
for each letter can be calculated using the following formula:

\[
\frac{\sqrt{2}^k - \sqrt{2} + 1}{\sqrt{2} - 1}
\]

\subsection{Frequent Counter}

The \textbf{FrequentCount} class implements a Frequent Counter as a Data Stream Algorithm. The goal is to establish an estimate for the frequency of any stream letter. The frequent count algorithm implemented was the Misra & Gries algorithm. This uses a parameter \textit{k} that controls the quality of the results given. It uses a \textit{{letter: counter}} dictionary, with at most \textit{(k - 1)} counters, at any time.
This algorithm provides, for any letter, \textit{l}, a frequency estimate satisfying

\[
f_l - \frac{m}{k} \leq f_{l}^* \leq f_l
\]

were \textit{m} is the length of the data stream or, in this case, the total number of letters in the text. If some letter has \(f_l > \frac{m}{k}\), its counter \textit{A[l]} will be positive, i.e., no item with frequency \(\frac{m}{k}\) is missed.

\subsection{Tests}

The \textbf{tests.py} contains the logic of the tests that are used to compute the results for the Decreasing Probability and Frequent counters, comparing both to the Exact Counter. The obtained results will be discussed in the next section.

\section{Results and Discussion}

As mentioned in the previous subsection, some tests were developed and used to compare both algorithms. 
Regarding the Decreasing Probability Counter, the following measures were computed: absolute error (mean, minimum, and maximum), relative error (mean, minimum, and maximum), standard deviation, and variance. All measures were calculated as an average from one hundred trials, and the comparison was made using the estimated count from each letter from the text.
Regarding the Frequent Counter, due to being a deterministic algorithm, the results are always the same. So, one run of the tests gives the results needed for comparison. For this counter, the \textit{k} most frequent letters were computed.
For both tests, the literary work used was \textit{Crime and Punishment, by Fyodor Dostoevsky} in both English and Spanish languages. Inside the \textbf{/texts/} folder, \textit{The Metamorphosis, by Franz Kafka} can also be found, in both English and German languages.

\subsection{Decreasing Probability Counter}

The figure \ref{decressing_probability_cp_en} shows the results for the \textit{Crime and Punishment, by Fyodor Dostoevsky} text, in English, which has, without the stop-words, \textit{874218} letters.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=1\columnwidth]{./figures/decressing_probability_cp_en.png}
    \caption{Results obtained using the Decreasing Probability Counter, in English\label{decressing_probability_cp_en}}
    \label{fig: decressing_probability_cp_en}
\end{figure}

From these results, there are a few conclusions we can take. For each letter, the expected (estimated) value has a high deviation from the real value. This can be confirmed by the mean absolute and relative error columns. Taking, for example, the letter \textit{E}, the mean relative error is \textit{34.4\%}, meaning that the accuracy of the results is less than \textit{70\%}, which I believe is not a bad result, considering that this algorithm only increments each letter's counter with probability \(\frac{1}{\sqrt{2}^k}\). There is also a relatively high standard deviation, and thus, variance. On the other hand, memory-wise this method is much more efficient than the exact count. It is worth mentioning that there are some letters whose mean relative error is \textit{0.0\%}, translating into a \textit{100\%} accuracy.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=1\columnwidth]{./figures/decressing_probability_cp_es.png}
    \caption{Results obtained using the Decreasing Probability Counter, in Spanish\label{decressing_probability_cp_es}}
    \label{fig: decressing_probability_cp_es}
\end{figure}

Let's take a look at the results for the same literary work, but this time in Spanish, in figure \ref{decressing_probability_cp_es}. Comparing both languages, and even though they are different, we can see that, for the top 10 most frequent letters, the letters \textit{E}, \textit{T}, \textit{A}, \textit{O}, \textit{N}, \textit{I}, \textit{S}, \textit{R}, and \textit{D} are common in both, despite not all of them having the same relative order.

\begin{figure}[!htb]
    \centering
    \subfloat[\centering English]{{\includegraphics[width=2.5cm]{./figures/decressing_probability_top10_en.png} }}%
    \qquad
    \subfloat[\centering Spanish]{{\includegraphics[width=2.5cm]{./figures/decressing_probability_top10_es.png} }}%
    \caption{Comparison Between Top 10 Most Frequent Letters in English and Spanish\label{comparison_top10}}%
    \label{fig:example}%
\end{figure}

In \ref{comparison_top10}, we can see a direct comparison between the top 10 most frequent letters in both English and Spanish languages.

\subsection{Frequent Counter}

Both figures \ref{comparison_frequent_en} and \ref{comparison_frequent_es} show the comparisons made for the frequent counter, on both English and Spanish languages, with \textit{k} as 5, 10, and 20.
One thing worth mentioning is that, for higher values of \textit{k}, the algorithm gives us more accurate results, as this literally work is large.

\begin{figure}[!htb]
    \centering
    \subfloat[\centering \textit{k = 5}]{{\includegraphics[width=2cm]{./figures/frequent_count_k_5_cp_en.png} }}%
    \qquad
    \subfloat[\centering \textit{k = 10}]{{\includegraphics[width=2cm]{./figures/frequent_count_k_10_cp_en.png} }}%
    \qquad
    \subfloat[\centering \textit{k = 20}]{{\includegraphics[width=2cm]{./figures/frequent_count_k_20_cp_en.png} }}%
    \caption{Comparison Between Frequent Counter for \textit{k = 5, 10, and 20, in English}\label{comparison_frequent_en}}%
    \label{fig:example}%
\end{figure}

\begin{figure}[!htb]
    \centering
    \subfloat[\centering \textit{k = 5}]{{\includegraphics[width=2cm]{./figures/frequent_count_k_5_cp_es.png} }}%
    \qquad
    \subfloat[\centering \textit{k = 10}]{{\includegraphics[width=2cm]{./figures/frequent_count_k_10_cp_es.png} }}%
    \qquad
    \subfloat[\centering \textit{k = 20}]{{\includegraphics[width=2cm]{./figures/frequent_count_k_20_cp_es.png} }}%
    \caption{Comparison Between Frequent Counter for \textit{k = 5, 10, and 20, in Spanish}\label{comparison_frequent_es}}%
    \label{fig:example}%
\end{figure}

In both languages, taking for example \textit{k = 20}, and as seen on the decreasing probability counter, some of the most frequent letters are the same, although in a different relative order. Compared with the exact count, if a letter has a frequency larger or equal to \(\frac{m}{k}\), the order in which it appears on the table is the same as in the exact count.

\section{Conclusion}

This assignment allowed for a better understanding of the difference between probabilistic counter and data stream algorithms. Both the decreasing probability counter and the frequent counter can be good solutions to reducing memory usage, even though they have different applications, as the use cases differ between the two. Regarding future work, it would be relevant to compare the algorithms explored with different ones, to have an even better term of comparison and knowledge about this type of counting methods.

\begin{thebibliography}{9}

\bibitem{project}
Project Gutenberg. (1971-2021). Welcome to Project Gutenberg.\url{https://www.gutenberg.org/}

\bibitem{regular_expressions}
Python Software Foundation. (Dec 22, 2022). re â Regular expression operations. \url{https://docs.python.org/3/library/re.html}

\bibitem{abstract_base_classes}
Python Software Foundation. (Dec 22, 2022). abc â Abstract Base Classes. \url{https://docs.python.org/3/library/abc.html}

\bibitem{aproximate_counting_algorithm}
Wikipedia contributors. (Dec 24, 2022). Approximate counting algorithm.  Wikipedia. \url{https://en.wikipedia.org/wiki/Approximate_counting_algorithm}

\bibitem{aproximate_counting_algorithm}
Wikipedia contributors. (Dec 24, 2022). Approximate counting algorithm.  Wikipedia. \url{https://en.wikipedia.org/wiki/Approximate_counting_algorithm}

\bibitem{aproximate_counting_algorithm}
Wikipedia contributors. (Jan 2, 2023). Streaming algorithm.  Wikipedia. \url{https://en.wikipedia.org/wiki/Streaming_algorithm#:~:text=In\%20computer\%20science\%2C\%20streaming\%20algorithms,passes\%20(typically\%20just\%20one)}

\end{thebibliography}

% use a field named url or \url{} for URLs
% Note: the \bibliographystyle is set automatically

\end{document}
